# render.yaml
#
# This configuration file tells Render how to build and deploy your
# Traffic Law AI Assistant.

services:
  # 1. Web Service for the Flask Chatbot
  - type: web
    name: traffic-law-bot
    env: python
    # Set the root directory to where your code is located
    rootDir: traffic_law_bot/chat-bot
    plan: standard # Or a plan that suits your needs. 'starter' might be too slow for model loading.
    buildCommand: |
      # Install dependencies
      pip install --upgrade pip
      pip install -r requirements.txt

      # Run the data ingestion pipeline. This runs on every deploy.
      # The ChromaDB data will be stored on the persistent disk.
      echo "Running document chunking..."
      python Step1_ingest_traffic_docs.py
      echo "Ingesting data into ChromaDB..."
      python Step2_ingest_to_chroma.py
    startCommand: "gunicorn --chdir . app:app --bind 0.0.0.0:$PORT"
    envVars:
      - key: OPENAI_API_KEY
        fromSecret: true # This will prompt you to create a secret in the Render dashboard
      - key: PYTHON_VERSION
        value: 3.12.2 # Match your local Python version
    # 2. Persistent Disk for ChromaDB
    disks:
      - name: chroma-data
        mountPath: /app/traffic_law_bot/chat-bot/chroma_db
        sizeGB: 1 # Adjust size if your DB grows larger